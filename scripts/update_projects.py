#!/usr/bin/env python3
"""
update_projects.py

Obtiene los repositorios p칰blicos m치s recientemente actualizados en GitHub
usando la API de b칰squeda. Busca solo repos actualizados desde la 칰ltima
ejecuci칩n (b칰squeda incremental tipo "tail -f").
"""
import os
import json
import sys
from datetime import datetime, timezone

import requests


def load_existing_data(out_path):
    """Carga datos existentes del JSON si existe"""
    if not os.path.exists(out_path):
        return None

    try:
        with open(out_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        print(f"丘멆잺  Error leyendo {out_path}: {e}", file=sys.stderr)
        return None


def format_datetime_for_search(dt_str):
    """Convierte ISO datetime a formato para GitHub Search (YYYY-MM-DDTHH:MM:SS)"""
    try:
        dt = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
        return dt.strftime("%Y-%m-%dT%H:%M:%S")
    except Exception:
        return None


def main():
    max_results = int(os.environ.get("MAX_RESULTS", "50"))
    min_stars = int(os.environ.get("MIN_STARS", "20"))
    out_path = os.environ.get("OUT_PATH", "data/projects.json")

    # Cargar datos existentes solo para obtener last_updated
    existing_data = load_existing_data(out_path)
    last_updated = None
    previous_count = 0

    if existing_data:
        last_updated = existing_data.get("last_updated")
        previous_count = existing_data.get("count", 0)
        if last_updated:
            print(f"游늰 칔ltima actualizaci칩n: {last_updated}", file=sys.stderr)
            print(f"游늭 Repos en consulta anterior: {previous_count}", file=sys.stderr)

    # URL de la API de b칰squeda de GitHub
    url = "https://api.github.com/search/repositories"

    # Query: repos con estrellas m칤nimas, ordenados por actualizaci칩n
    stars_query = f"stars:>={min_stars}" if min_stars > 0 else "stars:>=0"

    # Si tenemos 칰ltima fecha, buscar solo repos actualizados despu칠s
    if last_updated:
        formatted_date = format_datetime_for_search(last_updated)
        if formatted_date:
            stars_query += f" pushed:>{formatted_date}"
            print(f"游댌 Buscando repos actualizados despu칠s de {formatted_date}", file=sys.stderr)

    headers = {
        "Accept": "application/vnd.github+json",
        "User-Agent": "github-tail-fetcher",
    }

    token = os.environ.get("GH_API_TOKEN")
    if token:
        headers["Authorization"] = f"Bearer {token}"

    # GitHub API limita a 100 repos por p치gina, necesitamos m칰ltiples llamadas
    repos = []
    pages_needed = (max_results + 99) // 100  # Redondear hacia arriba

    print(f"游깷 Llamando a GitHub Search API ({pages_needed} p치gina(s))...", file=sys.stderr)

    for page in range(1, pages_needed + 1):
        params = {
            "q": stars_query,
            "sort": "updated",
            "order": "desc",
            "per_page": 100,
            "page": page
        }

        print(f"  游늯 P치gina {page}/{pages_needed}...", file=sys.stderr)
        resp = requests.get(url, params=params, headers=headers, timeout=20)

        # Manejo de rate limit
        if resp.status_code == 403:
            remaining = resp.headers.get("X-RateLimit-Remaining", "?")
            reset = resp.headers.get("X-RateLimit-Reset", "?")
            print(f"ERROR: Rate limit alcanzado. Remaining: {remaining}, Reset: {reset}", file=sys.stderr)
            sys.exit(1)

        resp.raise_for_status()
        data = resp.json()
        page_items = data.get("items", [])
        repos.extend(page_items)

        # Si esta p치gina tiene menos de 100, no hay m치s resultados
        if len(page_items) < 100:
            break

        # Guardar total_count de la primera p치gina
        if page == 1:
            total_available = data.get("total_count", 0)

    total_fetched = len(repos)
    print(f"游늵 Repos obtenidos en esta consulta: {total_fetched}", file=sys.stderr)
    print(f"游늳 Total disponible en GitHub: {total_available if 'total_available' in locals() else '?'}", file=sys.stderr)

    # Procesar repos de la consulta actual (sin acumular hist칩rico)
    current_projects = []

    for repo in repos:
        current_projects.append({
            "id": repo.get("id"),
            "name": repo.get("name"),
            "full_name": repo.get("full_name"),
            "html_url": repo.get("html_url"),
            "description": repo.get("description"),
            "stargazers_count": repo.get("stargazers_count"),
            "language": repo.get("language"),
            "updated_at": repo.get("updated_at"),
            "pushed_at": repo.get("pushed_at"),
            "fork": repo.get("fork"),
            "owner": {
                "login": repo.get("owner", {}).get("login"),
                "avatar_url": repo.get("owner", {}).get("avatar_url"),
                "html_url": repo.get("owner", {}).get("html_url"),
            },
        })

    # Ordenar por fecha de actualizaci칩n (m치s reciente primero)
    current_projects.sort(key=lambda x: x.get("updated_at") or "", reverse=True)

    # Limitar a max_results
    current_projects = current_projects[:max_results]

    os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)

    output_data = {
        "source": {
            "type": "github_search_repos",
            "query": stars_query,
            "min_stars": min_stars,
        },
        "last_updated": datetime.now(timezone.utc).isoformat(),
        "count": len(current_projects),
        "total_available": total_available if 'total_available' in locals() else 0,
        "projects": current_projects,
    }

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print(f"游 Guardados {len(current_projects)} repos de esta consulta", file=sys.stderr)


if __name__ == "__main__":
    main()
